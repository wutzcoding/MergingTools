{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv4AJaPbom19"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME: \"merged_model_v1\"\n",
        "yaml_config = \"\"\"\n",
        "MODEL_NAME: \"merged_240b_v1\"\n",
        "merge_method: linear\n",
        "parameters:\n",
        "  weight: 1.0\n",
        "slices:\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [0, 1]\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [0, 1]\n",
        "        parameters:\n",
        "          weight: 0\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [1, 20]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [10, 30]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [20, 40]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [30, 50]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [40, 60]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [50, 70]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [60, 80]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [70, 90]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [80, 100]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [90, 110]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [100, 120]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [110, 130]\n",
        "  - sources:\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [120, 139]\n",
        "      - model: wolfram/miquliz-120b-v2.0\n",
        "        layer_range: [120, 139]\n",
        "        parameters:\n",
        "          weight: 0\n",
        "dtype: float16\n",
        "tokenizer_source: model:wolfram/miquliz-120b-v2.0\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Save config as yaml file\n",
        "with open('config.yaml', 'w', encoding=\"utf-8\") as f:\n",
        "    f.write(yaml_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2UnV_uDjK5c",
        "outputId": "b4e02f84-f488-4fa8-8a22-f6acf9c15130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'mergekit'...\n",
            "remote: Enumerating objects: 1243, done.\u001b[K\n",
            "remote: Counting objects: 100% (614/614), done.\u001b[K\n",
            "remote: Compressing objects: 100% (219/219), done.\u001b[K\n",
            "remote: Total 1243 (delta 511), reused 411 (delta 393), pack-reused 629\u001b[K\n",
            "Receiving objects: 100% (1243/1243), 341.86 KiB | 10.36 MiB/s, done.\n",
            "Resolving deltas: 100% (847/847), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for mergekit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone -b mixtral https://github.com/cg123/mergekit.git\n",
        "!cd mergekit && pip install -qqq -e . --progress-bar off\n",
        "!pip install -qqq -U transformers --progress-bar off\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LiISkhaotvl"
      },
      "outputs": [],
      "source": [
        "!mergekit config.yaml merge --copy-tokenizer --allow-crimes --out-shard-size 1B --lazy-unpickle --device cuda --low-cpu-memory --trust-remote-code --i-understand-this-is-not-useful-without-training\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
